{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8k9WhT0VbEb0",
        "outputId": "f4e523f5-254a-42dc-e22f-06c60df8554a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.11.0 (from datasets)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Collecting responses<0.19 (from datasets)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.14.1 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T7_bdsb9I1W",
        "outputId": "9182757c-2392-4bfb-b578-7fc69ee8ead7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoModel, BertTokenizer\n",
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "HuZK-8FKhHWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = torch.cuda.get_device_name()\n",
        "n_gpu = torch.cuda.device_count()\n",
        "print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n",
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbQK5Ks39HnT",
        "outputId": "47816740-6135-4472-9dca-de170ffbed6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found device: Tesla T4, n_gpu: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2caBjrLim24j",
        "outputId": "0bb2fa6e-d4dd-487e-ed09-267dc98045a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_format(sentences):\n",
        "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "\n",
        "  for sentence in sentences:\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                          sentence,                      \n",
        "                          add_special_tokens = True, \n",
        "                          max_length = 64,           \n",
        "                          padding = 'max_length',\n",
        "                          truncation = True,\n",
        "                          return_attention_mask = True,   \n",
        "                          return_tensors = 'pt',     \n",
        "                    )\n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "  return input_ids, attention_masks\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
      ],
      "metadata": {
        "id": "0pZM4l8j4R7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_test_data(df):\n",
        "  df = df.reset_index(drop=True)\n",
        "\n",
        "  texts = df.Hypothesis.values\n",
        "  labels = df.Type.values\n",
        "\n",
        "  ### tokenize_and_format() is a helper function provided in helpers.py ###\n",
        "  input_ids, attention_masks = tokenize_and_format(texts)\n",
        "\n",
        "  # Convert the lists into tensors.\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  labels = torch.tensor(labels)\n",
        "  test_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(len(texts))]\n",
        "  test_text = [texts[i] for i in range(len(texts))]\n",
        "  return test_set, test_text"
      ],
      "metadata": {
        "id": "2ucRDsoo6jXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.modeling_bert import BertForSequenceClassification\n",
        "from transformers import RobertaForSequenceClassification\n",
        "from sklearn.metrics import classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# function to get validation accuracy\n",
        "# ADDED A PARAMETER FOR THE TEXT WHOSE PERFORMANCE IS BEING TESTED FOR FURTHER ANALYSIS\n",
        "batch_size = 8\n",
        "def get_test_performance(df,model_path,model_name):\n",
        "    # Put the model in evaluation mode\n",
        "    val_set,val_text = get_test_data(df)\n",
        "    if model_name == 'BERT':\n",
        "      model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "    elif model_name == 'ROBERTA':\n",
        "      model = RobertaForSequenceClassification.from_pretrained(model_path)\n",
        "    model.to('cuda')\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "\n",
        "    num_batches = int(len(val_set)/batch_size) + 1\n",
        "\n",
        "    total_correct = 0\n",
        "\n",
        "    #### TO GET AVG PERF OF ONE EPOCH #####\n",
        "    avg_accuracy_list=[]\n",
        "    avg_precision_list=[]\n",
        "    avg_recall_list=[]\n",
        "    avg_f1_list=[]\n",
        "    preds = []\n",
        "\n",
        "    for i in range(num_batches):\n",
        "\n",
        "      end_index = min(batch_size * (i+1), len(val_set))\n",
        "\n",
        "      batch = val_set[i*batch_size:end_index]\n",
        "      \n",
        "      if len(batch) == 0: continue\n",
        "\n",
        "      input_id_tensors = torch.stack([data[0] for data in batch])\n",
        "      input_mask_tensors = torch.stack([data[1] for data in batch])\n",
        "      label_tensors = torch.stack([data[2] for data in batch])\n",
        "      \n",
        "      # Move tensors to the GPU\n",
        "      b_input_ids = input_id_tensors.to(device)\n",
        "      b_input_mask = input_mask_tensors.to(device)\n",
        "      b_labels = label_tensors.to(device)\n",
        "        \n",
        "      # Tell pytorch not to bother with constructing the compute graph during\n",
        "      # the forward pass, since this is only needed for backprop (training).\n",
        "      with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        outputs = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "        \n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the number of correctly labeled examples in batch\n",
        "        pred_flat = np.argmax(logits, axis=1).flatten()\n",
        "        labels_flat = label_ids.flatten()\n",
        "        # ADDED CODE TO PRINT THE INCORRECTLY PREDICTED SENTENCE\n",
        "        for j in range(len(pred_flat)):\n",
        "          if pred_flat[j] != labels_flat[j]:\n",
        "            #pass\n",
        "            print(f\"Incorrectly predicted text: {val_text[i*batch_size+j]}; pred:{pred_flat[j]} ; GT:{labels_flat[j]}\")\n",
        "        num_correct = np.sum(pred_flat == labels_flat)\n",
        "        total_correct += num_correct\n",
        "        preds.extend(pred_flat)\n",
        "\n",
        "        ################## classification report for multiclass  ##################\n",
        "        report = classification_report(labels_flat, pred_flat, output_dict=True)\n",
        "        #print(\"Report\", report)\n",
        "\n",
        "        #extract the average values for each metric from the dictionary\n",
        "        accuracy= report['accuracy']\n",
        "        precision = report['macro avg']['precision'] \n",
        "        recall = report['macro avg']['recall']  \n",
        "        f1 = report['macro avg']['f1-score']\n",
        "\n",
        "        avg_accuracy_list.append(accuracy)\n",
        "        avg_precision_list.append(precision)\n",
        "        avg_recall_list.append(recall)\n",
        "        avg_f1_list.append(f1)\n",
        "\n",
        "        ################## classification report for multiclass  ##################      \n",
        "        \n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_correct / len(val_set)\n",
        "\n",
        "    avg_accuracy= sum(avg_accuracy_list) / len(avg_accuracy_list)\n",
        "    avg_precision= sum(avg_precision_list) / len(avg_precision_list)\n",
        "    avg_recall= sum(avg_recall_list) / len(avg_recall_list)\n",
        "    avg_f1=  sum(avg_f1_list) / len(avg_f1_list)\n",
        "\n",
        "    return avg_val_accuracy, avg_accuracy, avg_precision, avg_recall, avg_f1, preds\n",
        "\n"
      ],
      "metadata": {
        "id": "M6l2T3P53rmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ensemble model"
      ],
      "metadata": {
        "id": "xVsWi9zG5Lkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('../Datasets/Classification/test-set-predictions.csv',sep = ',')\n",
        "test_df['Type'].replace(['Metaphor', 'Idiom','Simile','Sarcasm'],[0,1,2,3], inplace=True)\n"
      ],
      "metadata": {
        "id": "kcd_pDfpqKGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_val_acc, avg_acc, avg_precision, avg_recall, avg_f1, preds = get_test_performance(test_df,'../Models/bert-CF-0.06','BERT')\n",
        "test_df['BERT'] = preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdcXgP-Lr4ho",
        "outputId": "65b22849-a3a4-45f7-b87b-091b52ffb3cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Incorrectly predicted text: Oh , and there 's one more thing you can be sure of , ’ he added sourly .; pred:1 ; GT:0\n",
            "Incorrectly predicted text: The tears cut both ways.; pred:0 ; GT:1\n",
            "Incorrectly predicted text: Armies are the main conventional weapon and have been around for over five millennia in various forms .; pred:0 ; GT:1\n",
            "Incorrectly predicted text: FROM 1984–90 guesses that cash flow could be higher if assets changed hands or if a firm 's financial structure was changed were made in $ 1.7 trillion - worth of cases in America .; pred:0 ; GT:1\n",
            "Incorrectly predicted text: I 've been too close up against it .; pred:0 ; GT:1\n",
            "Incorrectly predicted text: That movie was as disturbing as puppies; pred:0 ; GT:2\n",
            "Incorrectly predicted text: The judge is as honest as Pinocchio; pred:0 ; GT:2\n",
            "Incorrectly predicted text: Seeing the old juke box was like visiting a nasty, useless junkyard; pred:2 ; GT:0\n",
            "Incorrectly predicted text: The river is flowing like a rocket.; pred:2 ; GT:0\n",
            "Incorrectly predicted text: Iâm a Rolling Stone junkie, but the most I care about RS covers are when they donât put a legendary and recently deceased musician (Clarence) on it.; pred:1 ; GT:0\n",
            "Incorrectly predicted text: The rule of thumb for working out Maximum Heart Rate ( MHR ) is 225 minus your age in years .; pred:0 ; GT:1\n",
            "Incorrectly predicted text: The instrument was as easy to learn as astrophysics; pred:0 ; GT:2\n",
            "Incorrectly predicted text: The river flows like a stream of glass; pred:0 ; GT:2\n",
            "Incorrectly predicted text: The play was as thrilling as watching paint dry; pred:2 ; GT:0\n",
            "Incorrectly predicted text: It's a two-way street.; pred:0 ; GT:1\n",
            "Incorrectly predicted text: This was when violent members of the gay community struck out against police, and it was the start of the gay liberation movement; pred:1 ; GT:0\n",
            "Incorrectly predicted text: My friends asked if I would tickle the ivory at their wedding reception.; pred:0 ; GT:1\n",
            "Incorrectly predicted text: He wanted to bring the house down this time.; pred:0 ; GT:1\n",
            "Incorrectly predicted text: The good news I hear from feminist friends is that it's becoming old hat these days to involve the father in childbirth.; pred:3 ; GT:1\n",
            "Incorrectly predicted text: The world had always been handed to her on a silver platter.; pred:0 ; GT:1\n",
            "Incorrectly predicted text: in my book coincidences didn't really exist.; pred:0 ; GT:1\n",
            "Incorrectly predicted text: There may be no other country in the world that over the past half century has seen growth as sustained as that of South Korea, including conversions to Christ.; pred:1 ; GT:0\n",
            "Incorrectly predicted text: We got up way too early to catch a short flight to Paraguay.; pred:3 ; GT:0\n",
            "Incorrectly predicted text: This plane can fly like a dodo; pred:0 ; GT:2\n",
            "Incorrectly predicted text: Here comes the fool with his foggy brain.; pred:1 ; GT:0\n",
            "Incorrectly predicted text: The drawing was as round as a globe.; pred:2 ; GT:0\n",
            "Incorrectly predicted text: He is grinning like an ape.; pred:2 ; GT:0\n",
            "Incorrectly predicted text: The skin on your lips is thinner than other places on your body, only three layers compared to 16 on your face, which is why it is so crucially important that they are cared for, protected and not covered with noxious substances.; pred:2 ; GT:0\n",
            "Incorrectly predicted text: That is why it is so important to remain like a planted oak; pred:0 ; GT:2\n",
            "Incorrectly predicted text: That news was like a thick milkshake.; pred:2 ; GT:0\n",
            "Incorrectly predicted text: Recently , of course , there has been an added dimension — part media-and-politician inflated , part real : drugs .; pred:1 ; GT:0\n",
            "Incorrectly predicted text: The conversation was as juicy as a business meeting; pred:0 ; GT:2\n",
            "Incorrectly predicted text: And could we get your cell phone number to cross check records?; pred:0 ; GT:1\n",
            "Incorrectly predicted text: I take pride in the fact that a handful of people got a little something extra because of us that day.; pred:3 ; GT:1\n",
            "Incorrectly predicted text: The sprint was graceful as a fat man headed to his favorite all you can eat buffet.; pred:2 ; GT:0\n",
            "Incorrectly predicted text: Seeing the old juke box was like a key that opens a door of old memories.; pred:2 ; GT:0\n",
            "Incorrectly predicted text: £45,000 was the asking price and I was not surprised that the sale , so to speak , hung fire .; pred:1 ; GT:0\n",
            "Incorrectly predicted text: One senator should not have the power to arbitrarily kill such a promising proposal without being held accountable by the press or even his own party.; pred:1 ; GT:0\n",
            "Incorrectly predicted text: She said that she could smell infidelity from a mile.; pred:1 ; GT:0\n",
            "Incorrectly predicted text: You're as affectionate as a crocodile; pred:0 ; GT:2\n",
            "Incorrectly predicted text: I'm as hairy as a naked mole rat; pred:0 ; GT:2\n",
            "Incorrectly predicted text: He fought as hard as an opossum; pred:0 ; GT:2\n",
            "Incorrectly predicted text: The Taligent offering is a 32-bit operating environment being built from scratch around a new object model.; pred:0 ; GT:1\n",
            "Incorrectly predicted text: I'd kept it safe as houses on all my travelings here.; pred:0 ; GT:1\n",
            "Incorrectly predicted text: , Sophie rolling her eyes,'Oh, that news will go down like a lead balloon!; pred:2 ; GT:1\n",
            "Incorrectly predicted text: The robins are as thick today as flakes of snow were yesterday,; pred:0 ; GT:2\n",
            "Incorrectly predicted text: By the same token, new knowledge may be of little relevance to someone innovating a social instrument to satisfy a need that changing demographics or tax laws have created.; pred:0 ; GT:1\n",
            "Incorrectly predicted text: it was as predictable as a sandstorm.; pred:2 ; GT:0\n",
            "Incorrectly predicted text: He felt like a boxer who had been pummelled mercilessly against the ropes , on the verge of defeat , only to see his opponent 's corner throw in the towel .; pred:2 ; GT:1\n",
            "Incorrectly predicted text: As with most things which appeal to the vagaries of youthful fashion today's hit rapidly becomes old hat.; pred:0 ; GT:1\n",
            "Incorrectly predicted text: How have you weathered the storm ?; pred:0 ; GT:1\n",
            "Incorrectly predicted text: Water authorities that will make a splash: Jeremy Warner on investment in the floated water authorities; pred:0 ; GT:1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "1rT9Susw8SWs",
        "outputId": "9fe26db7-918c-45eb-b664-c01e55369332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0                                         Hypothesis  Type  \\\n",
              "0           748  The move was part of a radical ministerial res...     1   \n",
              "1           572         The clouds were as fluffy as cotton candy.     2   \n",
              "2           668  I wandered lonely as a cloud that floats on hi...     2   \n",
              "3           110                                 Honesty is a stain     0   \n",
              "4           479  I am absolutely in love with spiders and the t...     3   \n",
              "..          ...                                                ...   ...   \n",
              "826         423  She was waiting for me to talk about my past a...     1   \n",
              "827         346                  They'd make money hand over fist.     1   \n",
              "828         113               The dancer floated across the stage.     0   \n",
              "829         435          Could not  breed  ill-will between them ,     0   \n",
              "830         275                         Your smile is like an act.     2   \n",
              "\n",
              "        GPT-3  BERT  \n",
              "0       Idiom     1  \n",
              "1      Simile     2  \n",
              "2      Simile     2  \n",
              "3    Metaphor     0  \n",
              "4     Sarcasm     3  \n",
              "..        ...   ...  \n",
              "826     Idiom     1  \n",
              "827     Idiom     1  \n",
              "828  Metaphor     0  \n",
              "829  Metaphor     0  \n",
              "830    Simile     2  \n",
              "\n",
              "[831 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1bb9e156-52b7-4546-9f72-bb2d8d3a24b3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Hypothesis</th>\n",
              "      <th>Type</th>\n",
              "      <th>GPT-3</th>\n",
              "      <th>BERT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>748</td>\n",
              "      <td>The move was part of a radical ministerial res...</td>\n",
              "      <td>1</td>\n",
              "      <td>Idiom</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>572</td>\n",
              "      <td>The clouds were as fluffy as cotton candy.</td>\n",
              "      <td>2</td>\n",
              "      <td>Simile</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>668</td>\n",
              "      <td>I wandered lonely as a cloud that floats on hi...</td>\n",
              "      <td>2</td>\n",
              "      <td>Simile</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>110</td>\n",
              "      <td>Honesty is a stain</td>\n",
              "      <td>0</td>\n",
              "      <td>Metaphor</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>479</td>\n",
              "      <td>I am absolutely in love with spiders and the t...</td>\n",
              "      <td>3</td>\n",
              "      <td>Sarcasm</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>826</th>\n",
              "      <td>423</td>\n",
              "      <td>She was waiting for me to talk about my past a...</td>\n",
              "      <td>1</td>\n",
              "      <td>Idiom</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>827</th>\n",
              "      <td>346</td>\n",
              "      <td>They'd make money hand over fist.</td>\n",
              "      <td>1</td>\n",
              "      <td>Idiom</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>828</th>\n",
              "      <td>113</td>\n",
              "      <td>The dancer floated across the stage.</td>\n",
              "      <td>0</td>\n",
              "      <td>Metaphor</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>829</th>\n",
              "      <td>435</td>\n",
              "      <td>Could not  breed  ill-will between them ,</td>\n",
              "      <td>0</td>\n",
              "      <td>Metaphor</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>830</th>\n",
              "      <td>275</td>\n",
              "      <td>Your smile is like an act.</td>\n",
              "      <td>2</td>\n",
              "      <td>Simile</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>831 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1bb9e156-52b7-4546-9f72-bb2d8d3a24b3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1bb9e156-52b7-4546-9f72-bb2d8d3a24b3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1bb9e156-52b7-4546-9f72-bb2d8d3a24b3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(avg_val_acc, avg_acc, avg_precision, avg_recall, avg_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnaZQTyv9KWD",
        "outputId": "3b6c8633-f5ae-4a88-9b48-3053d7b8eedd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.937424789410349 0.9375 0.9110576923076924 0.9087606837606838 0.9015191405816402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_val_acc, avg_acc, avg_precision, avg_recall, avg_f1, preds = get_test_performance(test_df,'../Models/roberta-CF-0.02','ROBERTA')\n",
        "test_df['ROBERTA'] = preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZ0zvp8xICMD",
        "outputId": "921500bb-aff3-4c57-d914-1ba65f3df9fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Incorrectly predicted text: I wandered lonely as a cloud that floats on high o'er vales and hills.; pred:3 ; GT:2\n",
            "Incorrectly predicted text: They 'll make a point of finding suffering people.; pred:0 ; GT:1\n",
            "Incorrectly predicted text: Oh , and there 's one more thing you can be sure of , ’ he added sourly .; pred:1 ; GT:0\n",
            "Incorrectly predicted text: Armies are the main conventional weapon and have been around for over five millennia in various forms .; pred:0 ; GT:1\n",
            "Incorrectly predicted text: The ex-slave tasted freedom shortly before she died.; pred:1 ; GT:0\n",
            "Incorrectly predicted text: FROM 1984–90 guesses that cash flow could be higher if assets changed hands or if a firm 's financial structure was changed were made in $ 1.7 trillion - worth of cases in America .; pred:0 ; GT:1\n",
            "Incorrectly predicted text: That movie was as disturbing as puppies; pred:0 ; GT:2\n",
            "Incorrectly predicted text: I asked for your help and you disappeared from radar.; pred:1 ; GT:0\n",
            "Incorrectly predicted text: The judge is as honest as Pinocchio; pred:0 ; GT:2\n",
            "Incorrectly predicted text: I know that woman too well to ever want to lay a finger on her, okay?; pred:3 ; GT:1\n",
            "Incorrectly predicted text: The cake was as moist as the desert; pred:0 ; GT:2\n",
            "Incorrectly predicted text: Each blade of grass was a bayonet pointed firmly at our bare feet.; pred:1 ; GT:0\n",
            "Incorrectly predicted text: Seeing the old juke box was like visiting a nasty, useless junkyard; pred:2 ; GT:0\n",
            "Incorrectly predicted text: And dance as dust before the sun, light of foot and unconfined.; pred:1 ; GT:2\n",
            "Incorrectly predicted text: English earls were small beer by comparison to the margraves.; pred:0 ; GT:1\n",
            "Incorrectly predicted text: You’ve just made a breakthrough in AI that meant that our species became like landlines in the twenty-first century.; pred:1 ; GT:2\n",
            "Incorrectly predicted text: Clouds of every many dimensions bring graphic relief to a clear blue sky as they fan out over Sedona's southern monuments including Bell Rock, and Courthouse Butte.; pred:1 ; GT:0\n",
            "Incorrectly predicted text: Everyone agreed that the political newcomer gave the congressman a bloody nose during their first televised debate.; pred:0 ; GT:1\n",
            "Incorrectly predicted text: Ahab was a pyramid but I kept kicking at him.; pred:1 ; GT:0\n",
            "Incorrectly predicted text: The river is flowing like a rocket.; pred:2 ; GT:0\n",
            "Incorrectly predicted text: He shook his head without changing his expression.; pred:1 ; GT:0\n",
            "Incorrectly predicted text: Iâm a Rolling Stone junkie, but the most I care about RS covers are when they donât put a legendary and recently deceased musician (Clarence) on it.; pred:1 ; GT:0\n",
            "Incorrectly predicted text: she's light as a freight train; pred:0 ; GT:2\n",
            "Incorrectly predicted text: The spider that dropped down in front of me while driving delighted me; pred:0 ; GT:3\n",
            "Incorrectly predicted text: The classroom was as quiet as a tongue-tied librarian in a hybrid car.; pred:0 ; GT:2\n",
            "Incorrectly predicted text: Bear in mind that I said great, not decent enough to be mentioned in a Dominican pride flyer.; pred:3 ; GT:1\n",
            "Incorrectly predicted text: The mountains rose up like jagged teeth in the distance.; pred:0 ; GT:2\n",
            "Incorrectly predicted text: Whether it was a choice between the devil and the deep blue sea, I don't care.; pred:3 ; GT:1\n",
            "Incorrectly predicted text: The instrument was as easy to learn as astrophysics; pred:0 ; GT:2\n",
            "Incorrectly predicted text: VA mortgages are only made available to honorably discharged veterans and active service personnel who have met any of the following term of service requirements:; pred:3 ; GT:0\n",
            "Incorrectly predicted text: The fact that other fans recognise his behaviour as deplorable and ‘ beyond the pale’ is seen as proof that most fans have a tacit knowledge of the rules of disorder .; pred:3 ; GT:1\n",
            "Incorrectly predicted text: Can Desert Orchid the champion bring the house down and win .; pred:0 ; GT:1\n",
            "Incorrectly predicted text: For summer and his pleasures take flight on thee.; pred:1 ; GT:0\n",
            "Incorrectly predicted text: The river flows like a stream of glass; pred:0 ; GT:2\n",
            "Incorrectly predicted text: Exhausted .; pred:1 ; GT:0\n",
            "Incorrectly predicted text: God, I'm beautiful even with all these freaks still clambering over my back, stitching me up with all that snake-like twine theyd used in my operation, I look like a vogue model.; pred:3 ; GT:2\n",
            "Incorrectly predicted text: Now Paul will think twice .; pred:0 ; GT:1\n",
            "Incorrectly predicted text: I also hope that we will find out new and exciting areas for innovation potential that will drive new research and business opportunities, as well as job growth in the sector.; pred:3 ; GT:0\n",
            "Incorrectly predicted text: This is realpolitik run amok.’; pred:0 ; GT:1\n",
            "Incorrectly predicted text: You were mine — I knew that as soon as I set eyes on you.; pred:2 ; GT:1\n",
            "Incorrectly predicted text: Three hours later I was on hands and knees under the cotton trailer, as sick as a dog.; pred:3 ; GT:1\n",
            "Incorrectly predicted text: This was when violent members of the gay community struck out against police, and it was the start of the gay liberation movement; pred:3 ; GT:0\n",
            "Incorrectly predicted text: My friends asked if I would tickle the ivory at their wedding reception.; pred:3 ; GT:1\n",
            "Incorrectly predicted text: I was having difficulties with the underline of the hover state being cut off by the flash doc.; pred:3 ; GT:0\n",
            "Incorrectly predicted text: He was anxious like a lion.; pred:0 ; GT:2\n",
            "Incorrectly predicted text: And their which are guarded round the clock.; pred:0 ; GT:1\n",
            "Incorrectly predicted text: some peaks of demand can be dealt with by external consultants.; pred:1 ; GT:0\n",
            "Incorrectly predicted text: Yona really put it in a nutshell when she said I think er er you know behind closed doors the women worrying about what was gon na happen next you know they felt very frustrated and in a way it was a way to channel o our energies away; pred:3 ; GT:1\n",
            "Incorrectly predicted text: He wanted to bring the house down this time.; pred:0 ; GT:1\n",
            "Incorrectly predicted text: These goods are as valuable as treasure; pred:2 ; GT:0\n",
            "Incorrectly predicted text: He waited like a leopard poised to pounce; pred:0 ; GT:2\n",
            "Incorrectly predicted text: it dawned on him that she had betrayed him; pred:1 ; GT:0\n",
            "Incorrectly predicted text: By Thursday a run on money market funds was in full swing and we came as close to a meltdown as at any time since the 1930s.; pred:0 ; GT:1\n",
            "Incorrectly predicted text: It 's all water under the bridge ; you do n't want to hear it — I 'm sorry if you feel I 've been unfair to you .; pred:3 ; GT:1\n",
            "Incorrectly predicted text: Compared to their competitors' tech, this prototype looks like it has come from 4021; pred:2 ; GT:0\n",
            "Incorrectly predicted text: Thrilled with how two very responsible guys who RSVP'd for the flag football game didn't bother to show up, so I was stuck with a half-baked event.; pred:1 ; GT:3\n",
            "Incorrectly predicted text: Just in case I needed some motivation for him to calm down should he be inclined to go ballistic on me.; pred:3 ; GT:1\n",
            "Incorrectly predicted text: When it gets right down to the nuts and bolts of it, I'm flat-out lazy.; pred:3 ; GT:1\n",
            "Incorrectly predicted text: He has a brain like a sieve.; pred:2 ; GT:0\n",
            "Incorrectly predicted text: I have no idea how he did it, but he sure cut the gordian knot.“; pred:3 ; GT:1\n",
            "Incorrectly predicted text: Gwendolyn felt like an international woman of mystery who held all the answers to all the questions this loverboy could ask.; pred:3 ; GT:2\n",
            "Incorrectly predicted text: A wish with no strings attached whatsoever, as long as the judge approved it.; pred:2 ; GT:1\n",
            "Incorrectly predicted text: If you know of anyone in the north Minneapolis area whose home suffered structural damage please send the following information to WA Director Nick Jaeger at njaeger@mul.org; pred:1 ; GT:0\n",
            "Incorrectly predicted text: our new synthetic fabric breathes and is perfect for summer wear; pred:3 ; GT:0\n",
            "Incorrectly predicted text: But among political scientists and businesspeople the countryâs name has long suffered worst damage than this.; pred:1 ; GT:0\n",
            "Incorrectly predicted text: There may be no other country in the world that over the past half century has seen growth as sustained as that of South Korea, including conversions to Christ.; pred:1 ; GT:0\n",
            "Incorrectly predicted text: He had as much money as a mansion dweller; pred:2 ; GT:0\n",
            "Incorrectly predicted text: This hurts as much as eating chocolate; pred:2 ; GT:0\n",
            "Incorrectly predicted text: This plane can fly like a dodo; pred:0 ; GT:2\n",
            "Incorrectly predicted text: It was indeed my turn to run the gauntlet.; pred:3 ; GT:1\n",
            "Incorrectly predicted text: The drawing was as round as a globe.; pred:2 ; GT:0\n",
            "Incorrectly predicted text: The skin on your lips is thinner than other places on your body, only three layers compared to 16 on your face, which is why it is so crucially important that they are cared for, protected and not covered with noxious substances.; pred:1 ; GT:0\n",
            "Incorrectly predicted text: This expectation is met by meeting the regular course expectations of their teachers, and through participating in as many of the following extracurricular activities as possible: athletics, the arts, student government, campus ministry, etc.; pred:1 ; GT:0\n",
            "Incorrectly predicted text: That is why it is so important to remain like a planted oak; pred:3 ; GT:2\n",
            "Incorrectly predicted text: All fire-flush 'd when forest trees smoldered.; pred:1 ; GT:0\n",
            "Incorrectly predicted text: That news was like a thick milkshake.; pred:2 ; GT:0\n",
            "Incorrectly predicted text: All they wanted were his - not on your life!; pred:0 ; GT:1\n",
            "Incorrectly predicted text: Recently , of course , there has been an added dimension — part media-and-politician inflated , part real : drugs .; pred:1 ; GT:0\n",
            "Incorrectly predicted text: When he hid, he became an elephant.; pred:1 ; GT:0\n",
            "Incorrectly predicted text: while watching the movie, the emotion in the theatre was that of a very popular person's funeral; pred:1 ; GT:0\n",
            "Incorrectly predicted text: The conversation was as juicy as a business meeting; pred:0 ; GT:2\n",
            "Incorrectly predicted text: I take pride in the fact that a handful of people got a little something extra because of us that day.; pred:3 ; GT:1\n",
            "Incorrectly predicted text: Seeing the old juke box was like a key that opens a door of old memories.; pred:2 ; GT:0\n",
            "Incorrectly predicted text: That's as consistent as California weather; pred:2 ; GT:0\n",
            "Incorrectly predicted text: £45,000 was the asking price and I was not surprised that the sale , so to speak , hung fire .; pred:3 ; GT:0\n",
            "Incorrectly predicted text: One senator should not have the power to arbitrarily kill such a promising proposal without being held accountable by the press or even his own party.; pred:1 ; GT:0\n",
            "Incorrectly predicted text: you're as bright as a black hole; pred:2 ; GT:0\n",
            "Incorrectly predicted text: You're as affectionate as a crocodile; pred:0 ; GT:2\n",
            "Incorrectly predicted text: her ideas are as bright as heaven; pred:2 ; GT:0\n",
            "Incorrectly predicted text: He fought as hard as an opossum; pred:0 ; GT:2\n",
            "Incorrectly predicted text: It was a good performance that got my heart racing, even though I knew the act was like a street bought rolex.; pred:3 ; GT:2\n",
            "Incorrectly predicted text: This computer moves like an obese person in an electric scooter; pred:2 ; GT:0\n",
            "Incorrectly predicted text: Which horse are you backing?; pred:1 ; GT:0\n",
            "Incorrectly predicted text: Passing the buck; pred:0 ; GT:1\n",
            "Incorrectly predicted text: the ayes have it.; pred:0 ; GT:1\n",
            "Incorrectly predicted text: the food was as healthy as a gym membership; pred:2 ; GT:0\n",
            "Incorrectly predicted text: Mark ’s comments are an acid bath for my nerves.; pred:3 ; GT:0\n",
            "Incorrectly predicted text: I'd kept it safe as houses on all my travelings here.; pred:3 ; GT:1\n",
            "Incorrectly predicted text: Both access to and optimum utilization of water in rainfed areas is bringing considerable economic relief to single crop dependent farmer; with improvements in production and productivity being recorded.; pred:1 ; GT:0\n",
            "Incorrectly predicted text: The groups are as separate as Berlin during the Cold War.; pred:2 ; GT:0\n",
            "Incorrectly predicted text: , Sophie rolling her eyes,'Oh, that news will go down like a lead balloon!; pred:2 ; GT:1\n",
            "Incorrectly predicted text: it was as predictable as a sandstorm.; pred:2 ; GT:0\n",
            "Incorrectly predicted text: he 's been able to get round it really , it might well be above board , but the police have been looking into it; pred:3 ; GT:1\n",
            "Incorrectly predicted text: He felt like a boxer who had been pummelled mercilessly against the ropes , on the verge of defeat , only to see his opponent 's corner throw in the towel .; pred:2 ; GT:1\n",
            "Incorrectly predicted text: And his heart  outran  his footsteps ;; pred:1 ; GT:0\n",
            "Incorrectly predicted text: It wasn't as if he didn't already smoke like a chimney.; pred:2 ; GT:1\n",
            "Incorrectly predicted text: Benjamin went down on one knee , tugging at my sleeve for me to follow suit .; pred:3 ; GT:1\n",
            "Incorrectly predicted text: Water authorities that will make a splash: Jeremy Warner on investment in the floated water authorities; pred:0 ; GT:1\n",
            "Incorrectly predicted text: She was waiting for me to talk about my past and I figured there was no time like the present.; pred:3 ; GT:1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(avg_val_acc, avg_acc, avg_precision, avg_recall, avg_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lABc7AFu9NQh",
        "outputId": "e151187b-2c50-4095-ebfc-84694b419721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8688327316486161 0.8688186813186813 0.8331997863247865 0.8322783119658118 0.8154081450956452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['Type'].replace([0,1,2,3],['Metaphor', 'Idiom','Simile','Sarcasm'], inplace=True)\n",
        "test_df['BERT'].replace([0,1,2,3],['Metaphor', 'Idiom','Simile','Sarcasm'], inplace=True)\n",
        "test_df['ROBERTA'].replace([0,1,2,3],['Metaphor', 'Idiom','Simile','Sarcasm'], inplace=True)"
      ],
      "metadata": {
        "id": "bhME94zJ9YEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "VXZBVGjO9ioa",
        "outputId": "932e2355-0004-4d49-dbb3-2ac26c1c2a34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0                                         Hypothesis      Type  \\\n",
              "0           748  The move was part of a radical ministerial res...     Idiom   \n",
              "1           572         The clouds were as fluffy as cotton candy.    Simile   \n",
              "2           668  I wandered lonely as a cloud that floats on hi...    Simile   \n",
              "3           110                                 Honesty is a stain  Metaphor   \n",
              "4           479  I am absolutely in love with spiders and the t...   Sarcasm   \n",
              "..          ...                                                ...       ...   \n",
              "826         423  She was waiting for me to talk about my past a...     Idiom   \n",
              "827         346                  They'd make money hand over fist.     Idiom   \n",
              "828         113               The dancer floated across the stage.  Metaphor   \n",
              "829         435          Could not  breed  ill-will between them ,  Metaphor   \n",
              "830         275                         Your smile is like an act.    Simile   \n",
              "\n",
              "        GPT-3      BERT   ROBERTA  \n",
              "0       Idiom     Idiom     Idiom  \n",
              "1      Simile    Simile    Simile  \n",
              "2      Simile    Simile   Sarcasm  \n",
              "3    Metaphor  Metaphor  Metaphor  \n",
              "4     Sarcasm   Sarcasm   Sarcasm  \n",
              "..        ...       ...       ...  \n",
              "826     Idiom     Idiom   Sarcasm  \n",
              "827     Idiom     Idiom     Idiom  \n",
              "828  Metaphor  Metaphor  Metaphor  \n",
              "829  Metaphor  Metaphor  Metaphor  \n",
              "830    Simile    Simile    Simile  \n",
              "\n",
              "[831 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff9a763a-7457-439c-aee8-8dd8e209368f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Hypothesis</th>\n",
              "      <th>Type</th>\n",
              "      <th>GPT-3</th>\n",
              "      <th>BERT</th>\n",
              "      <th>ROBERTA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>748</td>\n",
              "      <td>The move was part of a radical ministerial res...</td>\n",
              "      <td>Idiom</td>\n",
              "      <td>Idiom</td>\n",
              "      <td>Idiom</td>\n",
              "      <td>Idiom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>572</td>\n",
              "      <td>The clouds were as fluffy as cotton candy.</td>\n",
              "      <td>Simile</td>\n",
              "      <td>Simile</td>\n",
              "      <td>Simile</td>\n",
              "      <td>Simile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>668</td>\n",
              "      <td>I wandered lonely as a cloud that floats on hi...</td>\n",
              "      <td>Simile</td>\n",
              "      <td>Simile</td>\n",
              "      <td>Simile</td>\n",
              "      <td>Sarcasm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>110</td>\n",
              "      <td>Honesty is a stain</td>\n",
              "      <td>Metaphor</td>\n",
              "      <td>Metaphor</td>\n",
              "      <td>Metaphor</td>\n",
              "      <td>Metaphor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>479</td>\n",
              "      <td>I am absolutely in love with spiders and the t...</td>\n",
              "      <td>Sarcasm</td>\n",
              "      <td>Sarcasm</td>\n",
              "      <td>Sarcasm</td>\n",
              "      <td>Sarcasm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>826</th>\n",
              "      <td>423</td>\n",
              "      <td>She was waiting for me to talk about my past a...</td>\n",
              "      <td>Idiom</td>\n",
              "      <td>Idiom</td>\n",
              "      <td>Idiom</td>\n",
              "      <td>Sarcasm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>827</th>\n",
              "      <td>346</td>\n",
              "      <td>They'd make money hand over fist.</td>\n",
              "      <td>Idiom</td>\n",
              "      <td>Idiom</td>\n",
              "      <td>Idiom</td>\n",
              "      <td>Idiom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>828</th>\n",
              "      <td>113</td>\n",
              "      <td>The dancer floated across the stage.</td>\n",
              "      <td>Metaphor</td>\n",
              "      <td>Metaphor</td>\n",
              "      <td>Metaphor</td>\n",
              "      <td>Metaphor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>829</th>\n",
              "      <td>435</td>\n",
              "      <td>Could not  breed  ill-will between them ,</td>\n",
              "      <td>Metaphor</td>\n",
              "      <td>Metaphor</td>\n",
              "      <td>Metaphor</td>\n",
              "      <td>Metaphor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>830</th>\n",
              "      <td>275</td>\n",
              "      <td>Your smile is like an act.</td>\n",
              "      <td>Simile</td>\n",
              "      <td>Simile</td>\n",
              "      <td>Simile</td>\n",
              "      <td>Simile</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>831 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff9a763a-7457-439c-aee8-8dd8e209368f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff9a763a-7457-439c-aee8-8dd8e209368f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff9a763a-7457-439c-aee8-8dd8e209368f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df[\"Max_pred\"] = [None]*test_df.shape[0]"
      ],
      "metadata": {
        "id": "nGSFMbNYNXqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#majority_voting\n",
        "from collections import Counter\n",
        "for i in range(test_df.shape[0]):\n",
        "  preds = test_df.loc[i,[\"GPT-3\",\"ROBERTA\",\"BERT\"]]\n",
        "  mapping = dict(Counter(preds))\n",
        "  max_label = sorted(mapping,key = mapping.get, reverse = True)[0]\n",
        "  test_df.loc[i,\"Max_pred\"] = max_label\n",
        "\n",
        "print(\"Ensemble accuracy:\",1-test_df[test_df.apply(lambda x:x.Type!=x.Max_pred, axis=1)].shape[0]/test_df.shape[0])"
      ],
      "metadata": {
        "id": "rGrgbuhzH6Md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errors = {\"GPT-3\":{\"BERT\":0,\"ROBERTA\":0,\"Both\":0, \"Count\":0},\"BERT\":{\"GPT-3\":0,\"ROBERTA\":0,\"Both\":0,\"Count\":0},\"ROBERTA\":{\"BERT\":0,\"GPT-3\":0,\"Both\":0,\"Count\":0}}\n",
        "for i in range(test_df.shape[0]):\n",
        "  actual = test_df.iloc[i].Type\n",
        "  gpt3 = test_df.iloc[i][\"GPT-3\"]==actual\n",
        "  bert = test_df.iloc[i][\"BERT\"]==actual\n",
        "  roberta = test_df.iloc[i][\"ROBERTA\"]==actual\n",
        "  if(not gpt3):\n",
        "    errors[\"GPT-3\"][\"Count\"]+=1\n",
        "    if(bert and roberta):\n",
        "      errors[\"GPT-3\"][\"Both\"]+=1\n",
        "    else:\n",
        "      if bert:\n",
        "        errors[\"GPT-3\"][\"BERT\"]+=1\n",
        "      elif roberta:\n",
        "        errors[\"GPT-3\"][\"ROBERTA\"]+=1\n",
        "  if(not bert):\n",
        "    errors[\"BERT\"][\"Count\"]+=1\n",
        "    if(gpt3 and roberta):\n",
        "      errors[\"BERT\"][\"Both\"]+=1\n",
        "    else:\n",
        "      if gpt3:\n",
        "        errors[\"BERT\"][\"GPT-3\"]+=1\n",
        "      elif roberta:\n",
        "        errors[\"BERT\"][\"ROBERTA\"]+=1\n",
        "  if(not roberta):\n",
        "    errors[\"ROBERTA\"][\"Count\"]+=1\n",
        "    if(bert and gpt3):\n",
        "      errors[\"ROBERTA\"][\"Both\"]+=1\n",
        "    else:\n",
        "      if bert:\n",
        "        errors[\"ROBERTA\"][\"BERT\"]+=1\n",
        "      elif gpt3:\n",
        "        errors[\"ROBERTA\"][\"GPT-3\"]+=1"
      ],
      "metadata": {
        "id": "ZetlxdnoDb4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0Kiy4ogHzHq",
        "outputId": "36b25871-e7c1-4361-aa76-ebbded073e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'GPT-3': {'BERT': 7, 'ROBERTA': 4, 'Both': 10, 'Count': 40},\n",
              " 'BERT': {'GPT-3': 13, 'ROBERTA': 4, 'Both': 16, 'Count': 52},\n",
              " 'ROBERTA': {'BERT': 7, 'GPT-3': 13, 'Both': 70, 'Count': 109}}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rU2NQxrCe8m7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}