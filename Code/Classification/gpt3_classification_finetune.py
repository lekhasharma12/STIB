# -*- coding: utf-8 -*-
"""gpt3_classification_finetune.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RVO4e0ETXtR5M9ScBLUoNtVPSxa45WoM
"""

# !pip install datasets
# !pip install transformers
# !pip install openai
# from datasets import load_dataset

import pandas as pd
import sklearn
from sklearn import metrics
import json
import openai
import time

api_key = "<replace_with_your_key>"
openai.api_key = api_key

from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

train_data = pd.read_csv('..Datasets/Classification/train-0.2.csv')[["Hypothesis","Type"]]
test_data = pd.read_csv('../Classification/test-0.2.csv')[["Hypothesis","Type"]]
# train_data[:,["Hypothesis","Type"]]

#run this only for finetuning
#create finetuning data
training_data = train_data.rename(columns = {"Hypothesis":"prompt","Type":"completion"})
training_data = training_data.sample(frac=1)
print(training_data)
training_data.to_json("train.jsonl", orient='records', lines=True)

#run this only for finetuning
!openai tools fine_tunes.prepare_data -f train.jsonl

#run this only for finetuning
!openai --api-key "<replace_with_your_key>" api fine_tunes.create -t 'train_prepared.jsonl' -m ada --n_epochs 4 --batch_size 16

#run this only for finetuning
#!openai --api-key "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" api fine_tunes.create -t 'train_prepared.jsonl' -m ada:ft-personal-2023-05-09-04-48-07 --n_epochs 1 --batch_size 16 --learning_rate_multiplier 0.1

#run this only for finetuning
!openai --api-key "<replace_with_your_key>" api fine_tunes.follow -i ft-9yzFGA1ozGylHQz5OvxOs6PK

!openai --api-key "<replace_with_your_key>" api fine_tunes.results -i ft-9yzFGA1ozGylHQz5OvxOs6PK > results.csv

import string
def get_pred(res, labels):
  text = res["choices"][0]["text"].translate(str.maketrans('', '', string.punctuation))
  pred_tokens = text.split(" ")
  # print(pred_tokens)
  pred = ""
  for i in pred_tokens:
    if i in labels:
      pred = i
      break
  return pred

def predict_single_sample(text):
  res = openai.Completion.create(model='ada:ft-personal-2023-05-15-01-40-58', prompt=text, temperature=0, top_p=1.0, max_tokens = 100)
  #print(res)
  return get_pred(res, ["Sarcasm","Simile","Metaphor","Idiom"])
  #return get_prob_of_all_labels(labels, logprobs)

#run this only for predicting
def test_model(df,model):
  c=0
  predictions = []
  for i in range(0,df.shape[0],60):
    for j in range(i,min(i+60, df.shape[0])):
      print(j)
      sample=df.iloc[j].Hypothesis
      print(sample)
      pred = predict_single_sample(sample)
      predictions.append(pred)
      print("Pred - ", pred," , Actual - ", df.iloc[j].Type)
      if(pred == df.iloc[j].Type):
        c+=1
        print("success")
      else:
        print("FAILURE")
    time.sleep(60)
  #df["Predictions"] = predictions
  return c/df.shape[0], predictions

#run this only for predicting
test_df = test_data.sample(frac=1)
acc, preds = test_model(test_df[:],'ada:ft-personal-2023-05-15-01-40-58')
test_df["Predictions"] = preds
#openai.Completion.create(model='ada:ft-personal-2023-04-23-23-59-37', prompt='I came across a snake outside my apartment and it made me feel like petting it', temperature=0, top_p=1.0, max_tokens = 4)

acc

test_df = test_df.rename(columns = {"Predictions":"GPT-3"})
test_df.to_csv("..Results/Classification/gpt_classification.csv")

#ada:ft-personal-2023-05-09-04-48-07 - 0.1,4 - 94.4
#ada:ft-personal-2023-05-06-04-30-30  - 0.05,4 - 95.8
#ada:ft-personal-2023-05-09-05-48-13 - 1,5 - 94.4

predict_single_sample("Porthleven harbour is frequently hit by storms and sometimes suffers severe damage as a result.")