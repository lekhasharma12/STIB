{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1oi-jjqg-S_"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install openai\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "import json\n",
        "import openai\n",
        "import time"
      ],
      "metadata": {
        "id": "qJh9xbhev_2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = \"<replace_with_your_key>\"\n",
        "openai.api_key = api_key"
      ],
      "metadata": {
        "id": "hltNWrbieiZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeybsGjrW6yq",
        "outputId": "8a143a66-5c5a-40d0-bb1f-7526c24fcfe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('..Datasets/Classification/train-0.2.csv')[[\"Hypothesis\",\"Type\"]]\n",
        "test_data = pd.read_csv('../Classification/test-0.2.csv')[[\"Hypothesis\",\"Type\"]]\n",
        "# train_data[:,[\"Hypothesis\",\"Type\"]]"
      ],
      "metadata": {
        "id": "4gHH5GpilLZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run this only for finetuning\n",
        "#create finetuning data\n",
        "training_data = train_data.rename(columns = {\"Hypothesis\":\"prompt\",\"Type\":\"completion\"})\n",
        "training_data = training_data.sample(frac=1)\n",
        "print(training_data)\n",
        "training_data.to_json(\"train.jsonl\", orient='records', lines=True)\n"
      ],
      "metadata": {
        "id": "CpZx-SqfNCkJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9ce7618-4d3f-48fe-fd85-dbc416ef4d14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 prompt completion\n",
            "2677  it was such a pleasant sight to see a guy pick...    Sarcasm\n",
            "3385    She had the madness of a 19th century hat maker   Metaphor\n",
            "4046       Their cause has the momentum of an avalanche   Metaphor\n",
            "5196        That my vengeance shall not  reach  him ! \"   Metaphor\n",
            "3123  Lawlessness prevailed, the kind of mind-sick v...      Idiom\n",
            "...                                                 ...        ...\n",
            "1663                      I had to strike now or never.      Idiom\n",
            "7354  This one was too healthy to pop his clogs in t...      Idiom\n",
            "1421  Your hair looks like a garden when the gardene...     Simile\n",
            "3486                        Your garden is like a mess.     Simile\n",
            "5030  The lion was as sleepy as a man on redbull and...   Metaphor\n",
            "\n",
            "[7480 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run this only for finetuning\n",
        "!openai tools fine_tunes.prepare_data -f train.jsonl "
      ],
      "metadata": {
        "id": "NBx1I1h5QLlc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d07a5f9e-768c-41ac-9017-1ad71b08738c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Your file contains 7480 prompt-completion pairs\n",
            "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
            "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
            "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
            "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
            "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: y\n",
            "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: y\n",
            "- [Recommended] Would you like to split into training and validation set? [Y/n]: n\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: y\n",
            "\n",
            "Wrote modified file to `train_prepared.jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"train_prepared.jsonl\"\n",
            "\n",
            "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt.\n",
            "Once your model starts training, it'll approximately take 3.03 hours to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run this only for finetuning\n",
        "!openai --api-key \"<replace_with_your_key>\" api fine_tunes.create -t 'train_prepared.jsonl' -m ada --n_epochs 4 --batch_size 16"
      ],
      "metadata": {
        "id": "FUyO9xbkQN4Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6b79889-82a1-4df7-9357-f0e54c72721d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found potentially duplicated files with name 'train_prepared.jsonl', purpose 'fine-tune' and size 911215 bytes\n",
            "file-AfFm2tzfT2peoQZSlwicU8gd\n",
            "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway: \n",
            "Upload progress: 100% 911k/911k [00:00<00:00, 444Mit/s]\n",
            "Uploaded file from train_prepared.jsonl: file-nDN9q4I3xbB8mkLJZgVPzjND\n",
            "Created fine-tune: ft-9yzFGA1ozGylHQz5OvxOs6PK\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2023-05-15 01:27:56] Created fine-tune: ft-9yzFGA1ozGylHQz5OvxOs6PK\n",
            "[2023-05-15 01:28:28] Fine-tune costs $0.26\n",
            "[2023-05-15 01:28:28] Fine-tune enqueued. Queue number: 0\n",
            "[2023-05-15 01:28:29] Fine-tune started\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run this only for finetuning\n",
        "#!openai --api-key \"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\" api fine_tunes.create -t 'train_prepared.jsonl' -m ada:ft-personal-2023-05-09-04-48-07 --n_epochs 1 --batch_size 16 --learning_rate_multiplier 0.1"
      ],
      "metadata": {
        "id": "JZRb8--M9t0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run this only for finetuning\n",
        "!openai --api-key \"<replace_with_your_key>\" api fine_tunes.follow -i ft-9yzFGA1ozGylHQz5OvxOs6PK"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMJxcXkRecPo",
        "outputId": "9dbbc2c7-434d-448d-d45c-7c0c9f024092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-05-15 01:27:56] Created fine-tune: ft-9yzFGA1ozGylHQz5OvxOs6PK\n",
            "[2023-05-15 01:28:28] Fine-tune costs $0.26\n",
            "[2023-05-15 01:28:28] Fine-tune enqueued. Queue number: 0\n",
            "[2023-05-15 01:28:29] Fine-tune started\n",
            "[2023-05-15 01:31:39] Completed epoch 1/4\n",
            "[2023-05-15 01:34:33] Completed epoch 2/4\n",
            "[2023-05-15 01:37:28] Completed epoch 3/4\n",
            "[2023-05-15 01:40:26] Completed epoch 4/4\n",
            "[2023-05-15 01:40:59] Uploaded model: ada:ft-personal-2023-05-15-01-40-58\n",
            "[2023-05-15 01:41:00] Uploaded result file: file-qwaGUPj1X6hL2lbW62pqHSZO\n",
            "[2023-05-15 01:41:00] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded ðŸŽ‰\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m ada:ft-personal-2023-05-15-01-40-58 -p <YOUR_PROMPT>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai --api-key \"<replace_with_your_key>\" api fine_tunes.results -i ft-9yzFGA1ozGylHQz5OvxOs6PK > results.csv"
      ],
      "metadata": {
        "id": "4lPGogj9OyDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "def get_pred(res, labels):\n",
        "  text = res[\"choices\"][0][\"text\"].translate(str.maketrans('', '', string.punctuation))\n",
        "  pred_tokens = text.split(\" \")\n",
        "  # print(pred_tokens)\n",
        "  pred = \"\"\n",
        "  for i in pred_tokens:\n",
        "    if i in labels:\n",
        "      pred = i\n",
        "      break\n",
        "  return pred\n",
        "\n",
        "def predict_single_sample(text):\n",
        "  res = openai.Completion.create(model='ada:ft-personal-2023-05-15-01-40-58', prompt=text, temperature=0, top_p=1.0, max_tokens = 100)\n",
        "  return get_pred(res, [\"Sarcasm\",\"Simile\",\"Metaphor\",\"Idiom\"])"
      ],
      "metadata": {
        "id": "ZA157sakTo8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run this only for predicting\n",
        "def test_model(df,model):\n",
        "  c=0\n",
        "  predictions = []\n",
        "  for i in range(0,df.shape[0],60):\n",
        "    for j in range(i,min(i+60, df.shape[0])):\n",
        "      print(j)\n",
        "      sample=df.iloc[j].Hypothesis\n",
        "      print(sample)\n",
        "      pred = predict_single_sample(sample)\n",
        "      predictions.append(pred)\n",
        "      print(\"Pred - \", pred,\" , Actual - \", df.iloc[j].Type)\n",
        "      if(pred == df.iloc[j].Type):\n",
        "        c+=1\n",
        "        print(\"success\")\n",
        "      else:\n",
        "        print(\"FAILURE\")\n",
        "    time.sleep(60)\n",
        "  return c/df.shape[0], predictions"
      ],
      "metadata": {
        "id": "L6g_PEC8IyaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run this only for predicting\n",
        "test_df = test_data.sample(frac=1)\n",
        "acc, preds = test_model(test_df[:],'ada:ft-personal-2023-05-15-01-40-58')\n",
        "test_df[\"Predictions\"] = preds"
      ],
      "metadata": {
        "id": "eGYMO6cpj0_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test_df.rename(columns = {\"Predictions\":\"GPT-3\"})\n",
        "test_df.to_csv(\"..Results/Classification/gpt_classification.csv\")"
      ],
      "metadata": {
        "id": "_sj1tep6rtiK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}